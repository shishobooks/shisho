# Job Logs Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Add a job logging system that persists logs to the database, enables viewing logs in the UI, and supports job failure states with proper error capture.

**Architecture:** New `job_logs` table stores per-job logs with level/message/data/stack_trace. A `JobLogger` wrapper writes to both DB and stdout. Worker integrates panic recovery and failure handling. Frontend displays logs with live-tailing and filtering.

**Tech Stack:** Go/Bun ORM, React/TypeScript, TanStack Query, SQLite FTS-style polling

---

## Task 1: Add JobLog Model

**Files:**
- Create: `pkg/models/job_log.go`

**Step 1: Create the JobLog model file**

```go
package models

import (
	"time"

	"github.com/uptrace/bun"
)

const (
	//tygo:emit export type JobLogLevel = typeof JobLogLevelInfo | typeof JobLogLevelWarn | typeof JobLogLevelError | typeof JobLogLevelFatal;
	JobLogLevelInfo  = "info"
	JobLogLevelWarn  = "warn"
	JobLogLevelError = "error"
	JobLogLevelFatal = "fatal"
)

type JobLog struct {
	bun.BaseModel `bun:"table:job_logs,alias:jl" tstype:"-"`

	ID         int       `bun:",pk,nullzero" json:"id"`
	CreatedAt  time.Time `json:"created_at"`
	JobID      int       `bun:",nullzero" json:"job_id"`
	Level      string    `bun:",nullzero" json:"level" tstype:"JobLogLevel"`
	Message    string    `bun:",nullzero" json:"message"`
	Data       *string   `json:"data,omitempty"`
	StackTrace *string   `json:"stack_trace,omitempty"`
}
```

**Step 2: Run `make tygo` to generate TypeScript types**

Run: `make tygo`
Expected: Types generated (or "Nothing to be done" if already up-to-date)

**Step 3: Commit**

```bash
git add pkg/models/job_log.go
git commit -m "feat(models): add JobLog model for job logging"
```

---

## Task 2: Add Failed Status to Job Model

**Files:**
- Modify: `pkg/models/job.go:11-16`

**Step 1: Update the JobStatus constants to include failed**

In `pkg/models/job.go`, update the const block:

```go
const (
	//tygo:emit export type JobStatus = typeof JobStatusPending | typeof JobStatusInProgress | typeof JobStatusCompleted | typeof JobStatusFailed;
	JobStatusPending    = "pending"
	JobStatusInProgress = "in_progress"
	JobStatusCompleted  = "completed"
	JobStatusFailed     = "failed"
)
```

**Step 2: Run `make tygo` to regenerate TypeScript types**

Run: `make tygo`
Expected: Types regenerated with new JobStatusFailed constant

**Step 3: Commit**

```bash
git add pkg/models/job.go
git commit -m "feat(models): add failed status to Job model"
```

---

## Task 3: Add JobRetentionDays Config

**Files:**
- Modify: `pkg/config/config.go:33-36`
- Modify: `shisho.example.yaml`

**Step 1: Add JobRetentionDays field to Config struct**

In `pkg/config/config.go`, add after `WorkerProcesses`:

```go
	// Job retention settings
	JobRetentionDays int `koanf:"job_retention_days" json:"job_retention_days"`
```

**Step 2: Add default value in defaults() function**

In `pkg/config/config.go`, in the `defaults()` function, add after `WorkerProcesses: 2,`:

```go
		JobRetentionDays:          30,
```

**Step 3: Update shisho.example.yaml**

Add after the `worker_processes` section:

```yaml

# How many days to retain completed/failed jobs (older jobs are deleted)
# Set to 0 to disable retention cleanup
# Env: JOB_RETENTION_DAYS
# Default: 30
job_retention_days: 30
```

**Step 4: Commit**

```bash
git add pkg/config/config.go shisho.example.yaml
git commit -m "feat(config): add job_retention_days configuration"
```

---

## Task 4: Create Database Migration for job_logs Table

**Files:**
- Create: `pkg/migrations/20260112000000_add_job_logs.go`

**Step 1: Create the migration file**

```go
package migrations

import (
	"context"

	"github.com/pkg/errors"
	"github.com/uptrace/bun"
)

func init() {
	up := func(_ context.Context, db *bun.DB) error {
		// Create job_logs table
		_, err := db.Exec(`
			CREATE TABLE job_logs (
				id INTEGER PRIMARY KEY AUTOINCREMENT,
				created_at TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
				job_id INTEGER NOT NULL REFERENCES jobs(id) ON DELETE CASCADE,
				level TEXT NOT NULL,
				message TEXT NOT NULL,
				data TEXT,
				stack_trace TEXT
			)
		`)
		if err != nil {
			return errors.WithStack(err)
		}

		// Index for fetching logs by job_id (most common query)
		_, err = db.Exec(`CREATE INDEX idx_job_logs_job_id ON job_logs(job_id)`)
		if err != nil {
			return errors.WithStack(err)
		}

		// Index for retention cleanup (delete old logs by created_at)
		_, err = db.Exec(`CREATE INDEX idx_job_logs_created_at ON job_logs(created_at)`)
		if err != nil {
			return errors.WithStack(err)
		}

		// Index for retention cleanup on jobs (delete old completed/failed jobs)
		_, err = db.Exec(`CREATE INDEX idx_jobs_status_created_at ON jobs(status, created_at)`)
		if err != nil {
			return errors.WithStack(err)
		}

		return nil
	}

	down := func(_ context.Context, db *bun.DB) error {
		_, err := db.Exec(`DROP INDEX IF EXISTS idx_jobs_status_created_at`)
		if err != nil {
			return errors.WithStack(err)
		}
		_, err = db.Exec(`DROP INDEX IF EXISTS idx_job_logs_created_at`)
		if err != nil {
			return errors.WithStack(err)
		}
		_, err = db.Exec(`DROP INDEX IF EXISTS idx_job_logs_job_id`)
		if err != nil {
			return errors.WithStack(err)
		}
		_, err = db.Exec(`DROP TABLE IF EXISTS job_logs`)
		return errors.WithStack(err)
	}

	Migrations.MustRegister(up, down)
}
```

**Step 2: Run `make start:air` to verify migration runs (or test with fresh DB)**

Run: `make start:air`
Expected: Server starts without migration errors

**Step 3: Commit**

```bash
git add pkg/migrations/20260112000000_add_job_logs.go
git commit -m "feat(migrations): add job_logs table and indexes"
```

---

## Task 5: Create JobLogs Service

**Files:**
- Create: `pkg/joblogs/service.go`

**Step 1: Create the service file with CRUD operations**

```go
package joblogs

import (
	"context"
	"time"

	"github.com/pkg/errors"
	"github.com/shishobooks/shisho/pkg/models"
	"github.com/uptrace/bun"
)

type ListJobLogsOptions struct {
	JobID   int
	AfterID *int
	Levels  []string
}

type Service struct {
	db *bun.DB
}

func NewService(db *bun.DB) *Service {
	return &Service{db}
}

func (svc *Service) CreateJobLog(ctx context.Context, log *models.JobLog) error {
	if log.CreatedAt.IsZero() {
		log.CreatedAt = time.Now()
	}

	_, err := svc.db.
		NewInsert().
		Model(log).
		Returning("*").
		Exec(ctx)
	if err != nil {
		return errors.WithStack(err)
	}

	return nil
}

func (svc *Service) ListJobLogs(ctx context.Context, opts ListJobLogsOptions) ([]*models.JobLog, error) {
	logs := []*models.JobLog{}

	q := svc.db.
		NewSelect().
		Model(&logs).
		Where("jl.job_id = ?", opts.JobID).
		Order("jl.id ASC")

	if opts.AfterID != nil {
		q = q.Where("jl.id > ?", *opts.AfterID)
	}

	if len(opts.Levels) > 0 {
		q = q.Where("jl.level IN (?)", bun.In(opts.Levels))
	}

	err := q.Scan(ctx)
	if err != nil {
		return nil, errors.WithStack(err)
	}

	return logs, nil
}
```

**Step 2: Commit**

```bash
git add pkg/joblogs/service.go
git commit -m "feat(joblogs): add service with CRUD operations"
```

---

## Task 6: Create JobLogger Wrapper

**Files:**
- Create: `pkg/joblogs/logger.go`

**Step 1: Create the logger wrapper**

```go
package joblogs

import (
	"context"
	"runtime/debug"

	"github.com/robinjoseph08/golib/logger"
	"github.com/segmentio/encoding/json"
	"github.com/shishobooks/shisho/pkg/models"
)

const maxDataValueLen = 1024

// JobLogger wraps logging to both stdout and database
type JobLogger struct {
	jobID   int
	service *Service
	log     logger.Logger
	ctx     context.Context
}

// NewJobLogger creates a new JobLogger for a specific job
func (svc *Service) NewJobLogger(ctx context.Context, jobID int, log logger.Logger) *JobLogger {
	return &JobLogger{
		jobID:   jobID,
		service: svc,
		log:     log.Data(logger.Data{"job_id": jobID}),
		ctx:     ctx,
	}
}

// Info logs an info-level message
func (l *JobLogger) Info(msg string, data logger.Data) {
	l.log.Info(msg, data)
	l.persist(models.JobLogLevelInfo, msg, data, nil)
}

// Warn logs a warning-level message
func (l *JobLogger) Warn(msg string, data logger.Data) {
	l.log.Warn(msg, data)
	l.persist(models.JobLogLevelWarn, msg, data, nil)
}

// Error logs an error-level message with automatic stack trace
func (l *JobLogger) Error(msg string, err error, data logger.Data) {
	l.log.Err(err).Error(msg, data)
	stack := string(debug.Stack())
	l.persist(models.JobLogLevelError, msg, data, &stack)
}

// Fatal logs a fatal-level message with automatic stack trace (for panics)
func (l *JobLogger) Fatal(msg string, err error, data logger.Data) {
	if data == nil {
		data = logger.Data{}
	}
	if err != nil {
		data["error"] = err.Error()
	}
	l.log.Error(msg, data)
	stack := string(debug.Stack())
	l.persist(models.JobLogLevelFatal, msg, data, &stack)
}

func (l *JobLogger) persist(level, msg string, data logger.Data, stackTrace *string) {
	var dataStr *string
	if data != nil && len(data) > 0 {
		// Truncate long values
		truncatedData := make(logger.Data)
		for k, v := range data {
			s, ok := v.(string)
			if ok && len(s) > maxDataValueLen {
				truncatedData[k] = truncateMiddle(s, maxDataValueLen)
			} else {
				truncatedData[k] = v
			}
		}
		jsonBytes, err := json.Marshal(truncatedData)
		if err == nil {
			s := string(jsonBytes)
			dataStr = &s
		}
	}

	jobLog := &models.JobLog{
		JobID:      l.jobID,
		Level:      level,
		Message:    msg,
		Data:       dataStr,
		StackTrace: stackTrace,
	}

	// Best effort - don't fail the job if logging fails
	_ = l.service.CreateJobLog(l.ctx, jobLog)
}

func truncateMiddle(s string, maxLen int) string {
	if len(s) <= maxLen {
		return s
	}
	half := (maxLen - 5) / 2
	return s[:half] + " ... " + s[len(s)-half:]
}
```

**Step 2: Commit**

```bash
git add pkg/joblogs/logger.go
git commit -m "feat(joblogs): add JobLogger wrapper for DB+stdout logging"
```

---

## Task 7: Create JobLogs Validators

**Files:**
- Create: `pkg/joblogs/validators.go`

**Step 1: Create the validators file**

```go
package joblogs

type ListJobLogsQuery struct {
	AfterID *int     `query:"after_id" json:"after_id,omitempty"`
	Level   []string `query:"level" json:"level,omitempty" validate:"dive,oneof=info warn error fatal"`
}
```

**Step 2: Commit**

```bash
git add pkg/joblogs/validators.go
git commit -m "feat(joblogs): add validators for API queries"
```

---

## Task 8: Create JobLogs Handlers

**Files:**
- Create: `pkg/joblogs/handlers.go`

**Step 1: Create the handlers file**

```go
package joblogs

import (
	"net/http"
	"strconv"

	"github.com/labstack/echo/v4"
	"github.com/pkg/errors"
	"github.com/shishobooks/shisho/pkg/errcodes"
	"github.com/shishobooks/shisho/pkg/jobs"
)

type handler struct {
	jobLogService *Service
	jobService    *jobs.Service
}

func (h *handler) listLogs(c echo.Context) error {
	ctx := c.Request().Context()

	jobID, err := strconv.Atoi(c.Param("id"))
	if err != nil {
		return errcodes.NotFound("Job")
	}

	// Verify job exists
	job, err := h.jobService.RetrieveJob(ctx, jobs.RetrieveJobOptions{
		ID: &jobID,
	})
	if err != nil {
		return errors.WithStack(err)
	}

	// Bind query params
	params := ListJobLogsQuery{}
	if err := c.Bind(&params); err != nil {
		return errors.WithStack(err)
	}

	logs, err := h.jobLogService.ListJobLogs(ctx, ListJobLogsOptions{
		JobID:   jobID,
		AfterID: params.AfterID,
		Levels:  params.Level,
	})
	if err != nil {
		return errors.WithStack(err)
	}

	resp := struct {
		Logs interface{} `json:"logs"`
		Job  interface{} `json:"job"`
	}{logs, job}

	return errors.WithStack(c.JSON(http.StatusOK, resp))
}
```

**Step 2: Commit**

```bash
git add pkg/joblogs/handlers.go
git commit -m "feat(joblogs): add HTTP handler for listing logs"
```

---

## Task 9: Create JobLogs Routes

**Files:**
- Create: `pkg/joblogs/routes.go`

**Step 1: Create the routes file**

```go
package joblogs

import (
	"github.com/labstack/echo/v4"
	"github.com/shishobooks/shisho/pkg/jobs"
	"github.com/uptrace/bun"
)

// RegisterRoutes registers job log routes on the jobs group
func RegisterRoutes(jobsGroup *echo.Group, db *bun.DB) {
	jobLogService := NewService(db)
	jobService := jobs.NewService(db)

	h := &handler{
		jobLogService: jobLogService,
		jobService:    jobService,
	}

	// GET /api/jobs/:id/logs
	jobsGroup.GET("/:id/logs", h.listLogs)
}
```

**Step 2: Commit**

```bash
git add pkg/joblogs/routes.go
git commit -m "feat(joblogs): add route registration"
```

---

## Task 10: Register JobLogs Routes in Main

**Files:**
- Modify: `cmd/api/main.go`

**Step 1: Find the route registration section and add joblogs import**

Add to imports:
```go
	"github.com/shishobooks/shisho/pkg/joblogs"
```

**Step 2: Find where jobs routes are registered and add joblogs routes after**

Find the line that registers jobs routes (something like `jobs.RegisterRoutesWithGroup`) and add after it:
```go
	joblogs.RegisterRoutes(jobsGroup, db)
```

**Step 3: Run `make check` to verify compilation**

Run: `make check`
Expected: All checks pass

**Step 4: Commit**

```bash
git add cmd/api/main.go
git commit -m "feat(api): register joblogs routes"
```

---

## Task 11: Add tygo Configuration for JobLogs

**Files:**
- Modify: `tygo.yaml`

**Step 1: Add joblogs package to tygo.yaml**

Add after the jobs package entry:
```yaml
  - path: "github.com/shishobooks/shisho/pkg/joblogs"
    output_path: "app/types/generated/joblogs.ts"
    include_files:
      - validators.go
```

**Step 2: Run `make tygo` to generate types**

Run: `make tygo`
Expected: `app/types/generated/joblogs.ts` is created

**Step 3: Export from types index**

Add to `app/types/index.ts`:
```typescript
export * from "./generated/joblogs";
```

**Step 4: Commit**

```bash
git add tygo.yaml app/types/index.ts
git commit -m "feat(types): add tygo config for joblogs types"
```

---

## Task 12: Add CleanupOldJobs to Jobs Service

**Files:**
- Modify: `pkg/jobs/service.go`

**Step 1: Add CleanupOldJobs method**

Add at the end of the service file:
```go
// CleanupOldJobs deletes completed and failed jobs older than the retention period.
// Associated job_logs are deleted automatically via ON DELETE CASCADE.
func (svc *Service) CleanupOldJobs(ctx context.Context, retentionDays int) (int64, error) {
	if retentionDays <= 0 {
		return 0, nil
	}

	cutoff := time.Now().AddDate(0, 0, -retentionDays)

	res, err := svc.db.NewDelete().
		Model((*models.Job)(nil)).
		Where("created_at < ?", cutoff).
		Where("status IN (?, ?)", models.JobStatusCompleted, models.JobStatusFailed).
		Exec(ctx)
	if err != nil {
		return 0, errors.WithStack(err)
	}

	count, err := res.RowsAffected()
	if err != nil {
		return 0, errors.WithStack(err)
	}

	return count, nil
}
```

**Step 2: Commit**

```bash
git add pkg/jobs/service.go
git commit -m "feat(jobs): add CleanupOldJobs for retention"
```

---

## Task 13: Integrate JobLogger into Worker

**Files:**
- Modify: `pkg/worker/worker.go`

**Step 1: Add joblogs import**

Add to imports:
```go
	"github.com/shishobooks/shisho/pkg/joblogs"
```

**Step 2: Add jobLogService field to Worker struct**

Add after `tagService *tags.Service`:
```go
	jobLogService *joblogs.Service
```

**Step 3: Initialize jobLogService in New function**

Add after `tagService := tags.NewService(db)`:
```go
	jobLogService := joblogs.NewService(db)
```

Add to the Worker struct initialization:
```go
		jobLogService:    jobLogService,
```

**Step 4: Update processFuncs map signature**

Change from:
```go
	processFuncs map[string]func(ctx context.Context, job *models.Job) error
```
To:
```go
	processFuncs map[string]func(ctx context.Context, job *models.Job, jobLog *joblogs.JobLogger) error
```

**Step 5: Update processJobs to use JobLogger with panic recovery**

Replace the processJobs function:

```go
func (w *Worker) processJobs() {
	for {
		select {
		case <-w.shutdown:
			w.doneProcessing <- struct{}{}
			return
		case job := <-w.queue:
			// Prep the context to be passed down to the process function.
			id, err := uuid.NewRandom()
			if err != nil {
				w.log.Err(err).Error("new uuid error")
				continue
			}
			log := w.log.ID(id.String()).Root(logger.Data{"job_id": job.ID, "type": job.Type, "process_id": processID})
			ctx := log.WithContext(context.Background())

			// Create job logger for DB persistence
			jobLog := w.jobLogService.NewJobLogger(ctx, job.ID, log)

			// Update job to be in progress and claimed by this process.
			job.Status = models.JobStatusInProgress
			job.ProcessID = &processID

			err = w.jobService.UpdateJob(ctx, job, jobs.UpdateJobOptions{
				Columns: []string{"status", "process_id"},
			})
			if err != nil {
				log.Err(err).Error("update job error")
				continue
			}

			// Process with panic recovery
			func() {
				defer func() {
					if r := recover(); r != nil {
						jobLog.Fatal("job panicked", fmt.Errorf("%v", r), logger.Data{"panic": r})
						job.Status = models.JobStatusFailed
						_ = w.jobService.UpdateJob(ctx, job, jobs.UpdateJobOptions{
							Columns: []string{"status"},
						})
					}
				}()

				// Find and invoke the appropriate process function.
				fn, ok := w.processFuncs[job.Type]
				if !ok {
					jobLog.Error("can't find process function for type", fmt.Errorf("unknown job type: %s", job.Type), nil)
					job.Status = models.JobStatusFailed
					_ = w.jobService.UpdateJob(ctx, job, jobs.UpdateJobOptions{
						Columns: []string{"status"},
					})
					return
				}

				err = fn(ctx, job, jobLog)
				if err != nil {
					jobLog.Error("job failed", err, nil)
					job.Status = models.JobStatusFailed
					_ = w.jobService.UpdateJob(ctx, job, jobs.UpdateJobOptions{
						Columns: []string{"status"},
					})
					return
				}

				// Update job to be completed so that it's not picked up anymore.
				job.Status = models.JobStatusCompleted
				err = w.jobService.UpdateJob(ctx, job, jobs.UpdateJobOptions{
					Columns: []string{"status"},
				})
				if err != nil {
					log.Err(err).Error("update job error")
				}
			}()
		}
	}
}
```

**Step 6: Add fmt import**

Add to imports:
```go
	"fmt"
```

**Step 7: Commit**

```bash
git add pkg/worker/worker.go
git commit -m "feat(worker): integrate JobLogger with panic recovery"
```

---

## Task 14: Update ProcessScanJob Signature and Replace Logging

**Files:**
- Modify: `pkg/worker/scan.go`

**Step 1: Update function signature**

Change from:
```go
func (w *Worker) ProcessScanJob(ctx context.Context, _ *models.Job) error {
```
To:
```go
func (w *Worker) ProcessScanJob(ctx context.Context, _ *models.Job, jobLog *joblogs.JobLogger) error {
```

**Step 2: Add joblogs import**

Add to imports:
```go
	"github.com/shishobooks/shisho/pkg/joblogs"
```

**Step 3: Replace log calls with jobLog calls**

In ProcessScanJob, replace the main log calls with jobLog calls. Key replacements:

- `log := logger.FromContext(ctx)` - remove this line
- `log.Info("processing scan job")` -> `jobLog.Info("processing scan job", nil)`
- `log.Info("processing libraries", logger.Data{"count": len(allLibraries)})` -> `jobLog.Info("processing libraries", logger.Data{"count": len(allLibraries)})`
- `log.Info("processing library", logger.Data{"library_id": library.ID})` -> `jobLog.Info("processing library", logger.Data{"library_id": library.ID})`
- And so on for other log calls in the function...

For the scanFile helper function and other internal functions that use `log := logger.FromContext(ctx)`, keep those using the context-based logger (not jobLog) since they are internal operations that don't need to be surfaced to the user.

**Note:** Only replace the high-level log calls in ProcessScanJob itself. The scanFile and other helper functions can continue to use the context logger for detailed internal logging.

**Step 4: Run `make check` to verify compilation**

Run: `make check`
Expected: All checks pass

**Step 5: Commit**

```bash
git add pkg/worker/scan.go
git commit -m "feat(worker): update scan job to use JobLogger"
```

---

## Task 15: Add Retention Cleanup to Worker

**Files:**
- Modify: `pkg/worker/worker.go`

**Step 1: Add retention cleanup goroutine in Start function**

Add after the scheduleScanJobs goroutine setup:
```go
	if w.config.JobRetentionDays > 0 {
		go w.cleanupOldJobs()
	}
```

**Step 2: Add doneCleanup channel to Worker struct**

Add after `doneScheduling chan struct{}`:
```go
	doneCleanup    chan struct{}
```

**Step 3: Initialize doneCleanup in New function**

Add after `doneScheduling: make(chan struct{})`:
```go
		doneCleanup:    make(chan struct{}),
```

**Step 4: Add cleanupOldJobs function**

Add after scheduleScanJobs function:
```go
func (w *Worker) cleanupOldJobs() {
	// Run cleanup hourly
	duration := 1 * time.Hour
	timer := time.NewTimer(duration)

	for {
		select {
		case <-w.shutdown:
			timer.Stop()
			w.doneCleanup <- struct{}{}
			return
		case <-timer.C:
			ctx := context.Background()
			log := w.log.Root(logger.Data{"cleanup": "jobs"})

			count, err := w.jobService.CleanupOldJobs(ctx, w.config.JobRetentionDays)
			if err != nil {
				log.Err(err).Error("failed to cleanup old jobs")
			} else if count > 0 {
				log.Info("cleaned up old jobs", logger.Data{"count": count})
			}
			timer.Reset(duration)
		}
	}
}
```

**Step 5: Update Shutdown to wait for doneCleanup**

Add before the closing brace of Shutdown:
```go
	if w.config.JobRetentionDays > 0 {
		<-w.doneCleanup
	}
```

**Step 6: Commit**

```bash
git add pkg/worker/worker.go
git commit -m "feat(worker): add hourly job retention cleanup"
```

---

## Task 16: Update Jobs List Status Filter to Include Failed

**Files:**
- Modify: `pkg/jobs/validators.go`

**Step 1: Update the Status validation to include failed**

Change from:
```go
	Status []string `query:"status" json:"status,omitempty" validate:"dive,oneof=pending in_progress completed"`
```
To:
```go
	Status []string `query:"status" json:"status,omitempty" validate:"dive,oneof=pending in_progress completed failed"`
```

**Step 2: Run `make tygo` to regenerate types**

Run: `make tygo`
Expected: Types regenerated

**Step 3: Commit**

```bash
git add pkg/jobs/validators.go
git commit -m "feat(jobs): add failed status to list filter validation"
```

---

## Task 17: Create useJobLogs Query Hook

**Files:**
- Modify: `app/hooks/queries/jobs.ts`

**Step 1: Add JobLog import and useJobLogs query**

Add to the QueryKey enum:
```typescript
  ListJobLogs = "ListJobLogs",
```

Add the interface and hook:
```typescript
interface ListJobLogsData {
  logs: JobLog[];
  job: Job;
}

interface UseJobLogsOptions {
  afterId?: number;
  level?: string[];
}

export const useJobLogs = (
  jobId?: string,
  options: UseJobLogsOptions = {},
  queryOptions: Omit<
    UseQueryOptions<ListJobLogsData, ShishoAPIError>,
    "queryKey" | "queryFn"
  > = {},
) => {
  return useQuery<ListJobLogsData, ShishoAPIError>({
    enabled: queryOptions.enabled !== undefined ? queryOptions.enabled : Boolean(jobId),
    ...queryOptions,
    queryKey: [QueryKey.ListJobLogs, jobId, options],
    queryFn: ({ signal }) => {
      const params: Record<string, string | string[]> = {};
      if (options.afterId !== undefined) {
        params.after_id = String(options.afterId);
      }
      if (options.level && options.level.length > 0) {
        params.level = options.level;
      }
      return API.request("GET", `/jobs/${jobId}/logs`, null, params, signal);
    },
  });
};
```

**Step 2: Add JobLog import from types**

Update the types import:
```typescript
import type { CreateJobPayload, Job, JobLog, ListJobsQuery } from "@/types";
```

**Step 3: Commit**

```bash
git add app/hooks/queries/jobs.ts
git commit -m "feat(hooks): add useJobLogs query hook"
```

---

## Task 18: Create JobDetail Page Component

**Files:**
- Create: `app/components/pages/JobDetail.tsx`

**Step 1: Create the JobDetail component**

```typescript
import { formatDistanceToNow } from "date-fns";
import { ArrowLeft, ChevronDown, ChevronRight } from "lucide-react";
import { useCallback, useEffect, useRef, useState } from "react";
import { Link, useParams } from "react-router-dom";

import LoadingSpinner from "@/components/library/LoadingSpinner";
import { Badge } from "@/components/ui/badge";
import { Button } from "@/components/ui/button";
import { Checkbox } from "@/components/ui/checkbox";
import { Input } from "@/components/ui/input";
import { useJobLogs } from "@/hooks/queries/jobs";
import {
  JobLogLevelError,
  JobLogLevelFatal,
  JobLogLevelInfo,
  JobLogLevelWarn,
  JobStatusInProgress,
  JobStatusPending,
  type JobLog,
} from "@/types";

const getLevelColor = (level: string) => {
  switch (level) {
    case JobLogLevelInfo:
      return "bg-blue-500/20 text-blue-400";
    case JobLogLevelWarn:
      return "bg-yellow-500/20 text-yellow-400";
    case JobLogLevelError:
      return "bg-red-500/20 text-red-400";
    case JobLogLevelFatal:
      return "bg-red-700/30 text-red-300";
    default:
      return "bg-gray-500/20 text-gray-400";
  }
};

const getStatusColor = (status: string) => {
  switch (status) {
    case "completed":
      return "bg-green-100 text-green-800 dark:bg-green-900/30 dark:text-green-400";
    case "in_progress":
      return "bg-blue-100 text-blue-800 dark:bg-blue-900/30 dark:text-blue-400";
    case "pending":
      return "bg-yellow-100 text-yellow-800 dark:bg-yellow-900/30 dark:text-yellow-400";
    case "failed":
      return "bg-red-100 text-red-800 dark:bg-red-900/30 dark:text-red-400";
    default:
      return "bg-gray-100 text-gray-800 dark:bg-gray-900/30 dark:text-gray-400";
  }
};

const formatDuration = (start: string, end?: string | null): string => {
  const startDate = new Date(start);
  const endDate = end ? new Date(end) : new Date();
  const durationMs = endDate.getTime() - startDate.getTime();

  if (durationMs < 1000) {
    return `${durationMs}ms`;
  }
  const seconds = Math.floor(durationMs / 1000);
  if (seconds < 60) {
    return `${seconds}s`;
  }
  const minutes = Math.floor(seconds / 60);
  const remainingSeconds = seconds % 60;
  return `${minutes}m ${remainingSeconds}s`;
};

interface LogEntryProps {
  log: JobLog;
  searchTerm: string;
}

const LogEntry = ({ log, searchTerm }: LogEntryProps) => {
  const [expanded, setExpanded] = useState(false);
  const hasExpandableContent = log.data || log.stack_trace;

  const timestamp = new Date(log.created_at).toLocaleTimeString();

  // Parse data if present
  let parsedData: Record<string, unknown> | null = null;
  if (log.data) {
    try {
      parsedData = JSON.parse(log.data);
    } catch {
      parsedData = null;
    }
  }

  // Create data preview
  const dataPreview = parsedData
    ? Object.entries(parsedData)
        .map(([k, v]) => `${k}=${JSON.stringify(v)}`)
        .join(" ")
    : null;

  // Highlight search term in message
  const highlightText = (text: string) => {
    if (!searchTerm) return text;
    const regex = new RegExp(`(${searchTerm})`, "gi");
    const parts = text.split(regex);
    return parts.map((part, i) =>
      regex.test(part) ? (
        <mark className="bg-yellow-300 dark:bg-yellow-700" key={i}>
          {part}
        </mark>
      ) : (
        part
      ),
    );
  };

  return (
    <div className="py-2 border-b border-border last:border-b-0 font-mono text-sm">
      <div
        className={`flex items-start gap-2 ${hasExpandableContent ? "cursor-pointer" : ""}`}
        onClick={() => hasExpandableContent && setExpanded(!expanded)}
      >
        {hasExpandableContent ? (
          expanded ? (
            <ChevronDown className="h-4 w-4 mt-0.5 text-muted-foreground flex-shrink-0" />
          ) : (
            <ChevronRight className="h-4 w-4 mt-0.5 text-muted-foreground flex-shrink-0" />
          )
        ) : (
          <div className="w-4 flex-shrink-0" />
        )}
        <span className="text-muted-foreground flex-shrink-0">{timestamp}</span>
        <Badge className={`${getLevelColor(log.level)} flex-shrink-0`} variant="secondary">
          {log.level}
        </Badge>
        <span className="text-foreground">{highlightText(log.message)}</span>
        {dataPreview && !expanded && (
          <span className="text-muted-foreground truncate">{dataPreview}</span>
        )}
      </div>
      {expanded && (
        <div className="ml-6 mt-2 space-y-2">
          {parsedData && (
            <pre className="bg-muted p-2 rounded text-xs overflow-x-auto">
              {JSON.stringify(parsedData, null, 2)}
            </pre>
          )}
          {log.stack_trace && (
            <pre className="bg-red-950/20 p-2 rounded text-xs overflow-x-auto text-red-400">
              {log.stack_trace}
            </pre>
          )}
        </div>
      )}
    </div>
  );
};

const JobDetail = () => {
  const { id } = useParams<{ id: string }>();
  const [searchTerm, setSearchTerm] = useState("");
  const [levelFilter, setLevelFilter] = useState<string[]>([]);
  const [autoScroll, setAutoScroll] = useState(true);
  const logContainerRef = useRef<HTMLDivElement>(null);
  const lastLogIdRef = useRef<number | undefined>(undefined);

  const { data, isLoading, error, refetch } = useJobLogs(id, {
    level: levelFilter.length > 0 ? levelFilter : undefined,
  });

  const job = data?.job;
  const logs = data?.logs ?? [];

  // Filter logs by search term (client-side)
  const filteredLogs = logs.filter((log) => {
    if (!searchTerm) return true;
    const searchLower = searchTerm.toLowerCase();
    if (log.message.toLowerCase().includes(searchLower)) return true;
    if (log.data?.toLowerCase().includes(searchLower)) return true;
    return false;
  });

  // Polling for live updates
  useEffect(() => {
    if (job?.status === JobStatusPending || job?.status === JobStatusInProgress) {
      const interval = setInterval(refetch, 2000);
      return () => clearInterval(interval);
    }
  }, [job?.status, refetch]);

  // Auto-scroll to bottom when new logs arrive
  useEffect(() => {
    if (autoScroll && logContainerRef.current && filteredLogs.length > 0) {
      const lastLog = filteredLogs[filteredLogs.length - 1];
      if (lastLog.id !== lastLogIdRef.current) {
        lastLogIdRef.current = lastLog.id;
        logContainerRef.current.scrollTop = logContainerRef.current.scrollHeight;
      }
    }
  }, [filteredLogs, autoScroll]);

  // Disable auto-scroll when user scrolls up
  const handleScroll = useCallback(() => {
    if (logContainerRef.current) {
      const { scrollTop, scrollHeight, clientHeight } = logContainerRef.current;
      const isAtBottom = scrollHeight - scrollTop - clientHeight < 50;
      if (!isAtBottom && autoScroll) {
        setAutoScroll(false);
      }
    }
  }, [autoScroll]);

  const toggleLevelFilter = (level: string) => {
    setLevelFilter((prev) =>
      prev.includes(level) ? prev.filter((l) => l !== level) : [...prev, level],
    );
  };

  if (isLoading) {
    return <LoadingSpinner />;
  }

  if (error) {
    return (
      <div className="text-center">
        <h1 className="text-2xl font-semibold mb-4">Error Loading Job</h1>
        <p className="text-muted-foreground">{error.message}</p>
      </div>
    );
  }

  if (!job) {
    return (
      <div className="text-center">
        <h1 className="text-2xl font-semibold mb-4">Job Not Found</h1>
      </div>
    );
  }

  return (
    <div className="h-full flex flex-col">
      {/* Header */}
      <div className="mb-6">
        <Link
          className="inline-flex items-center text-sm text-muted-foreground hover:text-foreground mb-4"
          to="/settings/jobs"
        >
          <ArrowLeft className="h-4 w-4 mr-1" />
          Back to Jobs
        </Link>
        <div className="flex items-center gap-4">
          <h1 className="text-2xl font-semibold">Job #{job.id}</h1>
          <Badge className={getStatusColor(job.status)} variant="secondary">
            {job.status === JobStatusInProgress ? "running" : job.status}
          </Badge>
        </div>
        <div className="flex items-center gap-4 mt-2 text-sm text-muted-foreground">
          <span>Type: {job.type}</span>
          <span>Started {formatDistanceToNow(new Date(job.created_at))} ago</span>
          {job.status === JobStatusInProgress && (
            <span>Running for {formatDuration(job.created_at)}</span>
          )}
          {(job.status === "completed" || job.status === "failed") && job.updated_at && (
            <span>Took {formatDuration(job.created_at, job.updated_at)}</span>
          )}
          {job.process_id && <span>Process: {job.process_id}</span>}
        </div>
      </div>

      {/* Toolbar */}
      <div className="flex items-center gap-4 mb-4">
        <Input
          className="max-w-xs"
          onChange={(e) => setSearchTerm(e.target.value)}
          placeholder="Search logs..."
          type="text"
          value={searchTerm}
        />
        <div className="flex items-center gap-2">
          {[JobLogLevelInfo, JobLogLevelWarn, JobLogLevelError, JobLogLevelFatal].map((level) => (
            <Button
              className={levelFilter.includes(level) ? getLevelColor(level) : ""}
              key={level}
              onClick={() => toggleLevelFilter(level)}
              size="sm"
              variant={levelFilter.includes(level) ? "secondary" : "outline"}
            >
              {level}
            </Button>
          ))}
        </div>
      </div>

      {/* Log container */}
      <div
        className="flex-1 border border-border rounded-md bg-background overflow-y-auto min-h-0"
        onScroll={handleScroll}
        ref={logContainerRef}
      >
        <div className="p-4">
          {filteredLogs.length === 0 ? (
            <p className="text-muted-foreground text-center py-8">No logs found.</p>
          ) : (
            filteredLogs.map((log) => (
              <LogEntry key={log.id} log={log} searchTerm={searchTerm} />
            ))
          )}
        </div>
      </div>

      {/* Auto-scroll checkbox */}
      <div className="flex items-center gap-2 mt-4">
        <Checkbox
          checked={autoScroll}
          id="autoscroll"
          onCheckedChange={(checked) => {
            setAutoScroll(checked as boolean);
            if (checked && logContainerRef.current) {
              logContainerRef.current.scrollTop = logContainerRef.current.scrollHeight;
            }
          }}
        />
        <label className="text-sm text-muted-foreground" htmlFor="autoscroll">
          Auto-scroll to new logs
        </label>
      </div>
    </div>
  );
};

export default JobDetail;
```

**Step 2: Commit**

```bash
git add app/components/pages/JobDetail.tsx
git commit -m "feat(ui): add JobDetail page component"
```

---

## Task 19: Add JobDetail Route

**Files:**
- Modify: `app/router.tsx`

**Step 1: Import JobDetail component**

Add to imports:
```typescript
import JobDetail from "@/components/pages/JobDetail";
```

**Step 2: Add route for job detail page**

Add inside the settings children array, after the jobs route:
```typescript
      {
        path: "jobs/:id",
        element: (
          <ProtectedRoute
            requiredPermission={{ resource: "jobs", operation: "read" }}
          >
            <JobDetail />
          </ProtectedRoute>
        ),
      },
```

**Step 3: Commit**

```bash
git add app/router.tsx
git commit -m "feat(router): add job detail route"
```

---

## Task 20: Add Link to Job Detail from AdminJobs

**Files:**
- Modify: `app/components/pages/AdminJobs.tsx`

**Step 1: Import Link from react-router-dom (if not already imported)**

Verify `Link` is imported from `react-router-dom`.

**Step 2: Update JobRow to be a link**

Replace the JobRow component:
```typescript
const JobRow = ({ job }: JobRowProps) => (
  <Link
    className="flex items-center justify-between py-4 border-b border-border last:border-b-0 hover:bg-muted/50 -mx-6 px-6 transition-colors"
    to={`/settings/jobs/${job.id}`}
  >
    <div className="flex-1 min-w-0">
      <div className="flex items-center gap-3">
        <span className="font-medium text-foreground">{job.type}</span>
        <Badge className={getStatusColor(job.status)} variant="secondary">
          {job.status === JobStatusInProgress ? "running" : job.status}
        </Badge>
      </div>
      <div className="flex items-center gap-4 mt-1 text-sm text-muted-foreground">
        <span>Started {formatDistanceToNow(new Date(job.created_at))} ago</span>
        {job.status === JobStatusInProgress && job.created_at && (
          <span>Running for {formatDuration(job.created_at)}</span>
        )}
        {job.status === "completed" && job.created_at && job.updated_at && (
          <span>Took {formatDuration(job.created_at, job.updated_at)}</span>
        )}
      </div>
    </div>
  </Link>
);
```

**Step 3: Update imports**

Make sure `Link` is in the imports:
```typescript
import { Link, useSearchParams } from "react-router-dom";
```

**Step 4: Commit**

```bash
git add app/components/pages/AdminJobs.tsx
git commit -m "feat(ui): add links from job list to job detail"
```

---

## Task 21: Update AdminJobs to Show Failed Status

**Files:**
- Modify: `app/components/pages/AdminJobs.tsx`

**Step 1: Update getStatusColor to include failed**

Add a case for failed:
```typescript
    case "failed":
      return "bg-red-100 text-red-800 dark:bg-red-900/30 dark:text-red-400";
```

**Step 2: Import JobStatusFailed**

Update the types import to include `JobStatusFailed`:
```typescript
import { JobStatusFailed, JobStatusInProgress, JobTypeScan, type Job } from "@/types";
```

**Step 3: Update JobRow to show "failed" status properly**

In the Badge rendering, update to handle failed:
```typescript
          {job.status === JobStatusInProgress
            ? "running"
            : job.status === JobStatusFailed
              ? "failed"
              : job.status}
```

**Step 4: Update duration display for failed jobs**

Add another condition for showing duration:
```typescript
        {job.status === "failed" && job.created_at && job.updated_at && (
          <span>Took {formatDuration(job.created_at, job.updated_at)}</span>
        )}
```

**Step 5: Commit**

```bash
git add app/components/pages/AdminJobs.tsx
git commit -m "feat(ui): add failed status display to job list"
```

---

## Task 22: Run Full Test Suite and Fix Issues

**Files:**
- N/A

**Step 1: Run `make check` to verify everything compiles and passes**

Run: `make check`
Expected: All checks pass

**Step 2: Start the server and test manually**

Run: `make start`
Expected: Server starts without errors

**Step 3: Test the job logs feature**

1. Navigate to Settings > Jobs
2. Trigger a scan job
3. Click on the job to view its detail page
4. Verify logs appear and update in real-time
5. Test search and filter functionality
6. Verify auto-scroll works

**Step 4: Fix any issues found**

If any issues are found, fix them and commit with appropriate messages.

---

## Task 23: Final Commit and Cleanup

**Step 1: Run `make check` one final time**

Run: `make check`
Expected: All checks pass

**Step 2: Review all changes**

Run: `git diff master...HEAD --stat`
Expected: All expected files are modified/created

**Step 3: Create summary commit if needed**

If there are any uncommitted changes, commit them:
```bash
git add -A
git commit -m "chore: cleanup and final adjustments for job logs feature"
```

---

Plan complete and saved to `docs/plans/2026-01-12-job-logs.md`. Two execution options:

**1. Subagent-Driven (this session)** - I dispatch fresh subagent per task, review between tasks, fast iteration

**2. Parallel Session (separate)** - Open new session with executing-plans, batch execution with checkpoints

Which approach?
